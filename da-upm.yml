apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
    name: da-upm-template
spec:
    name: DA-UPM Template
    color: '#004e9c'
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
  name: inputs-net
spec:
  color: '#326BBA'
  name: inputs.net
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
  name: inputs-kernel
spec:
  color: '#326BBA'
  name: inputs.kernel
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
  name: inputs-disk
spec:
  color: '#326BBA'
  name: inputs.disk
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
  name: inputs-swap
spec:
  color: '#326BBA'
  name: inputs.swap
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
  name: inputs-system
spec:
  color: '#326BBA'
  name: inputs.system
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
  name: inputs-processes
spec:
  color: '#326BBA'
  name: inputs.processes
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
  name: inputs-diskio
spec:
  color: '#326BBA'
  name: inputs.diskio
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
  name: inputs-docker
spec:
  color: '#326BBA'
  name: inputs.docker
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
  name: outputs-influxdb-v2
spec:
  color: '#108174'
  name: outputs.influxdb_v2
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
  name: inputs-cpu
spec:
  color: '#326BBA'
  name: inputs.cpu
---
apiVersion: influxdata.com/v2alpha1
kind: Label
metadata:
  name: inputs-mem
spec:
  color: '#326BBA'
  name: inputs.mem
---
apiVersion: influxdata.com/v2alpha1
kind: Bucket
metadata:
  name: daupm
spec:
  name: daupm
  retentionRules:
    - everySeconds: 7776000
      type: expire
---
apiVersion: influxdata.com/v2alpha1
kind: Variable
metadata:
    name: linux-host
spec:
    name: linux_host
    associations:
      - kind: Label
        name: da-upm-template
    language: flux
    query: |-
        import "influxdata/influxdb/v1"
        v1.measurementTagValues(bucket: "daupm", measurement: "cpu", tag: "host")
    type: query
---
apiVersion: influxdata.com/v2alpha1
kind: CheckThreshold
metadata:
  name: container-mem-usage-pct
spec:
  description: El uso de memoria está por encima del 80% durante 5 minutos
  every: 5m0s
  name: Uso de memoria
  query: |-
    from(bucket: "daupm")
      |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
      |> filter(fn: (r) => r["_measurement"] == "docker_container_mem")
      |> filter(fn: (r) => r["_field"] == "usage_percent")
      |> aggregateWindow(every: 5m, fn: mean)
      |> yield(name: "mean")
  status: active
  statusMessageTemplate: '${ r._check_name } para el contenedor ${ r.container_name } en el host ${ r.engine_host }
        es: ${ r._level } '
  thresholds:
    - level: WARN
      type: greater
      value: 80
    - level: CRIT
      type: greater
      value: 90
    - level: OK
      type: lesser
      value: 80
---
apiVersion: influxdata.com/v2alpha1
kind: CheckThreshold
metadata:
  name: container-disk-usage-above-80
spec:
  description: El uso de disco está por encima del 80%
  every: 5m0s
  name: Uso de disco de los contedores
  query: |-
    from(bucket: "daupm")
      |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
      |> filter(fn: (r) => r["_measurement"] == "docker_container_blkio")
      |> filter(fn: (r) => r["_field"] == "usage_percent")
      |> aggregateWindow(every: 5m, fn: mean)
      |> yield(name: "mean")
  status: active
  statusMessageTemplate: '${ r._check_name } en el host ${ r.engine_host } es: ${ r._level }'
  thresholds:
    - level: WARN
      type: greater
      value: 80
    - level: CRIT
      type: greater
      value: 90
    - level: OK
      type: lesser
      value: 80
---
apiVersion: influxdata.com/v2alpha1
kind: CheckThreshold
metadata:
  name: container-non-zero-exit
spec:
  description: Un contendor ha finalizado la ejecución con un código distinto de 0
  every: 5m0s
  name: Código de salida distinto de 0
  query: |-
    from(bucket: "daupm")
      |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
      |> filter(fn: (r) => r["_measurement"] == "docker_container_status")
      |> filter(fn: (r) => r["_field"] == "exitcode")
      |> unique()
      |> yield(name: "unique")
  status: active
  statusMessageTemplate: '${ r._check_name } para el contenedor ${ r.container_name } en el host ${ r.engine_host }'
  thresholds:
    - level: CRIT
      max: 0
      min: 0
      type: outside_range
---
apiVersion: influxdata.com/v2alpha1
kind: CheckThreshold
metadata:
  name: container-cpu-usage-pct
spec:
  description: El uso de CPU está por encima del 80% durante 5 minutos
  every: 5m0s
  name: Uso de CPU
  query: |-
    from(bucket: "daupm")
      |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
      |> filter(fn: (r) => r["_measurement"] == "docker_container_cpu")
      |> filter(fn: (r) => r["_field"] == "usage_percent")
      |> aggregateWindow(every: 5m, fn: mean)
      |> yield(name: "mean")
  status: active
  statusMessageTemplate: '${ r._check_name } para el contenedor ${ r.container_name } en el host ${ r.engine_host }
        es: ${ r._level }'
  thresholds:
    - level: WARN
      type: greater
      value: 80
    - level: CRIT
      type: greater
      value: 90
    - level: OK
      type: lesser
      value: 80
---
apiVersion: influxdata.com/v2alpha1
kind: NotificationEndpointHTTP
metadata:
  name: daupm-custom-notification-endpoint
spec:
  method: POST
  name: HTTP POST
  status: active
  type: none
  url: http://172.18.0.12:3000/alert
---
apiVersion: influxdata.com/v2alpha1
kind: NotificationRule
metadata:
  name: crit-notifier
spec:
  endpointName: daupm-custom-notification-endpoint
  every: 5m0s
  name: Crit Notifier
  statusRules:
    - currentLevel: CRIT
      previousLevel: OK
---
apiVersion: influxdata.com/v2alpha1
kind: Dashboard
metadata:
  name: daupm-custom-dashboard
spec:
  associations:
    - kind: Label
      name: inputs-docker
    - kind: Label
      name: inputs-system
  charts:
    - height: 1
      kind: Markdown
      name: Name this Cell
      note: '# Docker Daemon'
      width: 12
      yPos: 1
    - colors:
        - hex: '#00C9FF'
          name: laser
          type: text
      decimalPlaces: 0
      height: 1
      kind: Single_Stat
      name: Num Images
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r["_measurement"] == "docker")
              |> filter(fn: (r) => r["_field"] == "n_images")
              |> filter(fn: (r) => r.host == v.linux_host)
      width: 2
      yPos: 2
    - height: 1
      kind: Markdown
      name: Name this Cell
      note: '# System Stats'
      width: 12
      yPos: 3
    - colors:
        - hex: '#00C9FF'
          name: laser
          type: text
      height: 1
      kind: Single_Stat
      name: System Uptime
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r["_measurement"] == "system")
              |> filter(fn: (r) => r["_field"] == "uptime")
              |> filter(fn: (r) => r.host == v.linux_host)
              |> map(fn: (r) => ({r with _value: float(v: r._value) / 86400.0}))
      suffix: ' days'
      width: 2
      yPos: 4
    - axes:
        - base: "10"
          name: x
          scale: linear
        - base: "2"
          name: y
          scale: linear
        - base: "10"
          name: y2
          scale: linear
      geom: line
      height: 2
      kind: Xy
      name: Swap
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r._measurement == "swap")
              |> filter(fn: (r) => r._field == "total" or r._field == "used")
              |> filter(fn: (r) => r.host == v.linux_host)
              |> window(period: v.windowPeriod)
              |> mean()
              |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
              |> yield(name: "mean")
      width: 3
      yPos: 5
    - axes:
        - base: "10"
          name: y2
          scale: linear
        - base: "10"
          name: x
          scale: linear
        - base: "2"
          label: Bytes
          name: y
          scale: linear
      geom: line
      height: 3
      kind: Xy
      name: Network TX trafic per container / sec
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop:v.timeRangeStop)
              |> filter(fn: (r) => r._measurement == "docker_container_net")
              |> filter(fn: (r) => r._field == "tx_bytes")
              |> filter(fn: (r) => r.host == v.linux_host)
              |> derivative(unit:1s, nonNegative: false)
              |> window(period: v.windowPeriod)
              |> mean()
              |> keep(columns: ["_measurement","container_name", "host","_value","_field","_stop"])
              |> group(columns: ["_value", "_time", "_start", "_stop"],mode: "except")
      width: 6
      xCol: _stop
      yCol: _value
      yPos: 7
    - height: 1
      kind: Markdown
      name: Name this Cell
      note: '# Container Stats'
      width: 12
      yPos: 10
    - axes:
        - base: "10"
          name: x
          scale: linear
        - base: "10"
          name: y
          scale: linear
          suffix: '%'
        - base: "10"
          name: y2
          scale: linear
      geom: line
      height: 3
      kind: Xy
      name: Disk Usage
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r._measurement == "disk")
              |> filter(fn: (r) => r._field == "used_percent")
              |> filter(fn: (r) => r.host == v.linux_host)
              |> window(period: v.windowPeriod)
              |> mean()
              |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
              |> yield(name: "mean")
      width: 3
      yPos: 11
    - colors:
        - hex: '#00C9FF'
          name: laser
          type: text
      decimalPlaces: 0
      height: 1
      kind: Single_Stat
      name: Total Num Containers
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r["_measurement"] == "docker")
              |> filter(fn: (r) => r["_field"] == "n_containers")
              |> filter(fn: (r) => r.host == v.linux_host)
      width: 2
      xPos: 2
      yPos: 2
    - colors:
        - hex: '#00C9FF'
          name: laser
          type: text
      decimalPlaces: 2
      height: 1
      kind: Single_Stat
      name: System Load
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r._measurement == "system")
              |> filter(fn: (r) => r._field == "load1")
              |> filter(fn: (r) => r.host == v.linux_host)
              |> window(period: v.windowPeriod)
              |> mean()
              |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
              |> yield(name: "mean")
      width: 1
      xPos: 2
      yPos: 4
    - axes:
        - base: "10"
          name: x
          scale: linear
        - base: "10"
          label: Load
          name: y
          scale: linear
        - base: "10"
          name: y2
          scale: linear
      geom: line
      height: 3
      kind: Xy
      name: System Load
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r._measurement == "system")
              |> filter(fn: (r) => r._field == "load1" or r._field == "load5" or r._field == "load15")
              |> filter(fn: (r) => r.host == v.linux_host)
              |> window(period: v.windowPeriod)
              |> mean()
              |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
              |> yield(name: "mean")
      width: 3
      xPos: 3
      yPos: 4
    - axes:
        - base: "10"
          name: x
          scale: linear
        - base: "10"
          name: y
          scale: linear
      geom: line
      height: 3
      kind: Xy
      name: Memory usage % per container
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r._measurement == "docker_container_mem")
              |> filter(fn: (r) => r._field == "usage_percent")
              |> filter(fn: (r) => r.host == v.linux_host)
              |> window(period: v.windowPeriod)
              |> mean()
              |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
              |> keep(columns: ["_measurement","container_name", "host","_value","_field","_stop"])
              |> yield(name: "mean")
      width: 3
      xPos: 3
      yPos: 11
    - colors:
        - hex: '#00C9FF'
          name: laser
          type: text
      decimalPlaces: 0
      height: 1
      kind: Single_Stat
      name: Number of Running Docker containers
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r["_measurement"] == "docker")
              |> filter(fn: (r) => r["_field"] == "n_containers_running")
              |> filter(fn: (r) => r.host == v.linux_host)
              |> group(columns: ["engine_host"])
      width: 2
      xPos: 4
      yPos: 2
    - colors:
        - hex: '#00C9FF'
          name: laser
          type: text
      decimalPlaces: 2
      height: 1
      kind: Single_Stat
      name: Docker Daemon nCPUs
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r._measurement == "docker")
              |> filter(fn: (r) => r._field == "n_cpus")
              |> filter(fn: (r) => r.host == v.linux_host)
              |> window(period: v.windowPeriod)
              |> last()
              |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
              |> yield(name: "last")
      suffix: ' cpus'
      width: 2
      xPos: 6
      yPos: 2
    - axes:
        - base: "10"
          name: x
          scale: linear
        - base: "10"
          name: y
          scale: linear
          suffix: '%'
      colors:
          - hex: '#00C9FF'
            name: laser
            type: text
      height: 3
      kind: Single_Stat_Plus_Line
      name: CPU Usage
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r._measurement == "cpu")
              |> filter(fn: (r) => r._field == "usage_system")
              |> filter(fn: (r) => r.cpu == "cpu-total")
              |> filter(fn: (r) => r.host == v.linux_host)
              |> window(period: v.windowPeriod)
              |> mean()
              |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
              |> yield(name: "mean")
      width: 3
      xPos: 6
      yPos: 4
    - axes:
        - base: "10"
          name: x
          scale: linear
        - base: "2"
          label: Bytes
          name: y
          scale: linear
        - base: "10"
          name: y2
          scale: linear
      colors:
        - hex: '#FDC44F'
          name: Cthulhu
          type: scale
        - hex: '#007C76'
          name: Cthulhu
          type: scale
        - hex: '#8983FF'
          name: Cthulhu
          type: scale
      geom: line
      height: 3
      kind: Xy
      name: Network RX trafic per container / sec
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r._measurement == "docker_container_net")
              |> filter(fn: (r) => r._field == "rx_bytes" )
              |> filter(fn: (r) => r.host == v.linux_host)
              |> derivative(unit: 1s, nonNegative: false)
              |> window(period: v.windowPeriod)
              |> mean()
              |> keep(columns: ["_measurement","container_name", "host","_value","_field","_stop"])
              |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
      width: 6
      xCol: _stop
      xPos: 6
      yCol: _value
      yPos: 7
    - axes:
        - base: "10"
          name: x
          scale: linear
        - base: "10"
          name: y
          scale: linear
      geom: line
      height: 3
      kind: Xy
      name: Memory usage per container
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r._measurement == "docker_container_mem")
              |> filter(fn: (r) => r._field == "usage")
              |> filter(fn: (r) => r.host == v.linux_host)
              |> window(period: v.windowPeriod)
              |> mean()
              |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
              |> keep(columns: ["_measurement","container_name", "host","_value","_field","_stop"])
              |> yield(name: "mean")
      width: 3
      xPos: 6
      yPos: 11
    - colors:
        - hex: '#00C9FF'
          name: laser
          type: text
      decimalPlaces: 2
      height: 1
      kind: Single_Stat
      name: Docker Daemon Total Mem
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r._measurement == "docker")
              |> filter(fn: (r) => r._field == "memory_total")
              |> filter(fn: (r) => r.host == v.linux_host)
              |> window(period: v.windowPeriod)
              |> last()
              |> map(fn: (r) => ({r with _value: float(v: r._value) / 1024.0 / 1024.0 / 1024.0}))
              |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
              |> yield(name: "last")
      suffix: ' GB'
      width: 2
      xPos: 8
      yPos: 2
    - axes:
        - base: "10"
          name: x
          scale: linear
        - base: "10"
          name: y
          scale: linear
          suffix: '%'
        - base: "10"
          name: y2
          scale: linear
      colors:
        - hex: '#00C9FF'
          name: laser
          type: text
        - hex: '#8F8AF4'
          name: Do Androids Dream of Electric Sheep?
          type: scale
        - hex: '#A51414'
          name: Do Androids Dream of Electric Sheep?
          type: scale
        - hex: '#F4CF31'
          name: Do Androids Dream of Electric Sheep?
          type: scale
      decimalPlaces: 1
      height: 3
      kind: Single_Stat_Plus_Line
      name: System Memory Usage
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r._measurement == "mem")
              |> filter(fn: (r) => r._field == "used_percent")
              |> filter(fn: (r) => r.host == v.linux_host)
              |> window(period: v.windowPeriod)
              |> mean()
              |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
              |> yield(name: "mean")
      suffix: '%'
      width: 3
      xCol: _stop
      xPos: 9
      yCol: _value
      yPos: 4
    - axes:
        - base: "10"
          name: x
          scale: linear
        - base: "10"
          name: y
          scale: linear
      geom: line
      height: 3
      kind: Xy
      name: CPU usage per container
      queries:
        - query: |-
            from(bucket: "daupm")
              |> range(start: v.timeRangeStart, stop: v.timeRangeStop)
              |> filter(fn: (r) => r._measurement == "cpu" or r._measurement == "docker_container_cpu")
              |> filter(fn: (r) => r._field == "usage_percent")
              |> filter(fn: (r) => r.host == v.linux_host)
              |> window(period: v.windowPeriod)
              |> mean()
              |> group(columns: ["_value", "_time", "_start", "_stop"], mode: "except")
              |> keep(columns: ["_measurement","container_name", "host","_value","_field","_stop"])
              |> yield(name: "mean")
      width: 3
      xPos: 9
      yPos: 11
  description: Panel de visualización del estado de los diferentes VPS a disposición de la Delegación de Alumnos de la UPM
  name: DA-UPM dashboard
---
apiVersion: influxdata.com/v2alpha1
kind: Telegraf
metadata:
  name: daupm-custom-telegraf-configuration
spec:
  associations:
    - kind: Label
      name: inputs-kernel
    - kind: Label
      name: inputs-mem
    - kind: Label
      name: inputs-swap
    - kind: Label
      name: inputs-processes
    - kind: Label
      name: inputs-diskio
    - kind: Label
      name: inputs-cpu
    - kind: Label
      name: inputs-net
    - kind: Label
      name: inputs-disk
    - kind: Label
      name: inputs-docker
    - kind: Label
      name: inputs-system
    - kind: Label
      name: outputs-influxdb-v2
  config: |
    # Telegraf Configuration
    #
    # Telegraf is entirely plugin driven. All metrics are gathered from the
    # declared inputs, and sent to the declared outputs.
    #
    # Plugins must be declared in here to be active.
    # To deactivate a plugin, comment out the name and any variables.
    #
    # Use 'telegraf -config telegraf.conf -test' to see what metrics a config
    # file would generate.
    #
    # Environment variables can be used anywhere in this config file, simply surround
    # them with ${}. For strings the variable must be within quotes (ie, "${STR_VAR}"),
    # for numbers and booleans they should be plain (ie, ${INT_VAR}, ${BOOL_VAR})


    # Global tags can be specified here in key="value" format.
    [global_tags]
      # dc = "us-east-1" # will tag all metrics with dc=us-east-1
      # rack = "1a"
      ## Environment variables can be used as tags, and throughout the config file
      # user = "$USER"


    # Configuration for telegraf agent
    [agent]
      ## Default data collection interval for all inputs
      interval = "10s"
      ## Rounds collection interval to 'interval'
      ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
      round_interval = true

      ## Telegraf will send metrics to outputs in batches of at most
      ## metric_batch_size metrics.
      ## This controls the size of writes that Telegraf sends to output plugins.
      metric_batch_size = 1000

      ## Maximum number of unwritten metrics per output.  Increasing this value
      ## allows for longer periods of output downtime without dropping metrics at the
      ## cost of higher maximum memory usage.
      metric_buffer_limit = 10000

      ## Collection jitter is used to jitter the collection by a random amount.
      ## Each plugin will sleep for a random time within jitter before collecting.
      ## This can be used to avoid many plugins querying things like sysfs at the
      ## same time, which can have a measurable effect on the system.
      collection_jitter = "0s"

      ## Default flushing interval for all outputs. Maximum flush_interval will be
      ## flush_interval + flush_jitter
      flush_interval = "10s"
      ## Jitter the flush interval by a random amount. This is primarily to avoid
      ## large write spikes for users running a large number of telegraf instances.
      ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
      flush_jitter = "0s"

      ## By default or when set to "0s", precision will be set to the same
      ## timestamp order as the collection interval, with the maximum being 1s.
      ##   ie, when interval = "10s", precision will be "1s"
      ##       when interval = "250ms", precision will be "1ms"
      ## Precision will NOT be used for service inputs. It is up to each individual
      ## service input to set the timestamp at the appropriate precision.
      ## Valid time units are "ns", "us" (or "µs"), "ms", "s".
      precision = ""

      ## Log at debug level.
      # debug = false
      ## Log only error level messages.
      # quiet = false

      ## Log target controls the destination for logs and can be one of "file",
      ## "stderr" or, on Windows, "eventlog".  When set to "file", the output file
      ## is determined by the "logfile" setting.
      # logtarget = "file"

      ## Name of the file to be logged to when using the "file" logtarget.  If set to
      ## the empty string then logs are written to stderr.
      # logfile = ""

      ## The logfile will be rotated after the time interval specified.  When set
      ## to 0 no time based rotation is performed.  Logs are rotated only when
      ## written to, if there is no log activity rotation may be delayed.
      # logfile_rotation_interval = "0d"

      ## The logfile will be rotated when it becomes larger than the specified
      ## size.  When set to 0 no size based rotation is performed.
      # logfile_rotation_max_size = "0MB"

      ## Maximum number of rotated archives to keep, any older logs are deleted.
      ## If set to -1, no archives are removed.
      # logfile_rotation_max_archives = 5

      ## Override default hostname, if empty use os.Hostname()
      hostname = "${DOCKER_TELEGRAF_HOSTNAME}"
      ## If set to true, do no set the "host" tag in the telegraf agent.
      omit_hostname = false


    ###############################################################################
    #                            OUTPUT PLUGINS                                   #
    ###############################################################################

    # Configuration for sending metrics to InfluxDB
    [[outputs.influxdb_v2]]
      ## The URLs of the InfluxDB cluster nodes.
      ##
      ## Multiple URLs can be specified for a single cluster, only ONE of the
      ## urls will be written to each interval.
      ##   ex: urls = ["https://us-west-2-1.aws.cloud2.influxdata.com"]
      urls = ["$INFLUX_HOST"]
      ## Token for authentication.
      token = "$INFLUX_TOKEN"
      ## Organization is the name of the organization you wish to write to; must exist.
      organization = "$INFLUX_ORG"
      ## Destination bucket to write into.
      bucket = "$INFLUX_BUCKET"
      ## The value of this tag will be used to determine the bucket.  If this
      ## tag is not set the 'bucket' option is used as the default.
      # bucket_tag = ""
      ## If true, the bucket tag will not be added to the metric.
      # exclude_bucket_tag = false
      ## Timeout for HTTP messages.
      # timeout = "5s"
      ## Additional HTTP headers
      # http_headers = {"X-Special-Header" = "Special-Value"}
      ## HTTP Proxy override, if unset values the standard proxy environment
      ## variables are consulted to determine which proxy, if any, should be used.
      # http_proxy = "http://corporate.proxy:3128"
      ## HTTP User-Agent
      # user_agent = "telegraf"
      ## Content-Encoding for write request body, can be set to "gzip" to
      ## compress body or "identity" to apply no encoding.
      # content_encoding = "gzip"
      ## Enable or disable uint support for writing uints influxdb 2.0.
      # influx_uint_support = false
      ## Optional TLS Config for use on HTTP connections.
      # tls_ca = "/etc/telegraf/ca.pem"
      # tls_cert = "/etc/telegraf/cert.pem"
      # tls_key = "/etc/telegraf/key.pem"
      ## Use TLS but skip chain & host verification
      # insecure_skip_verify = false

    ###############################################################################
    #                            INPUT PLUGINS                                    #
    ###############################################################################


    # Read metrics about cpu usage
    [[inputs.cpu]]
      ## Whether to report per-cpu stats or not
      percpu = true
      ## Whether to report total system cpu stats or not
      totalcpu = true
      ## If true, collect raw CPU time metrics.
      collect_cpu_time = false
      ## If true, compute and report the sum of all non-idle CPU states.
      report_active = false


    # Read metrics about disk usage by mount point
    [[inputs.disk]]
      ## By default stats will be gathered for all mount points.
      ## Set mount_points will restrict the stats to only the specified mount points.
      # mount_points = ["/"]

      ## Ignore mount points by filesystem type.
      ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]


    # Read metrics about disk IO by device
    [[inputs.diskio]]
      ## By default, telegraf will gather stats for all devices including
      ## disk partitions.
      ## Setting devices will restrict the stats to the specified devices.
      # devices = ["sda", "sdb", "vd*"]
      ## Uncomment the following line if you need disk serial numbers.
      # skip_serial_number = false
      #
      ## On systems which support it, device metadata can be added in the form of
      ## tags.
      ## Currently only Linux is supported via udev properties. You can view
      ## available properties for a device by running:
      ## 'udevadm info -q property -n /dev/sda'
      ## Note: Most, but not all, udev properties can be accessed this way. Properties
      ## that are currently inaccessible include DEVTYPE, DEVNAME, and DEVPATH.
      # device_tags = ["ID_FS_TYPE", "ID_FS_USAGE"]
      #
      ## Using the same metadata source as device_tags, you can also customize the
      ## name of the device via templates.
      ## The 'name_templates' parameter is a list of templates to try and apply to
      ## the device. The template may contain variables in the form of '$PROPERTY' or
      ## '${PROPERTY}'. The first template which does not contain any variables not
      ## present for the device is used as the device name tag.
      ## The typical use case is for LVM volumes, to get the VG/LV name instead of
      ## the near-meaningless DM-0 name.
      # name_templates = ["$ID_FS_LABEL","$DM_VG_NAME/$DM_LV_NAME"]


    # Get kernel statistics from /proc/stat
    [[inputs.kernel]]
      # no configuration


    # Read metrics about memory usage
    [[inputs.mem]]
      # no configuration

    # Read metrics about network interface usage
    [[inputs.net]]
      ## By default, telegraf gathers stats from any up interface (excluding loopback)
      ## Setting interfaces will tell it to gather these explicit interfaces,
      ## regardless of status.
      ##
      # interfaces = ["eth0"]
      ##
      ## On linux systems telegraf also collects protocol stats.
      ## Setting ignore_protocol_stats to true will skip reporting of protocol metrics.
      ##
      # ignore_protocol_stats = false
      ##

    # Get the number of processes and group them by status
    [[inputs.processes]]
      # no configuration


    # Read metrics about swap memory usage
    [[inputs.swap]]
      # no configuration


    # Read metrics about system load & uptime
    [[inputs.system]]
      ## Uncomment to remove deprecated metrics.
      # fielddrop = ["uptime_format"]


    [[inputs.docker]]
      endpoint = "unix:///var/run/docker.sock"
      gather_services = false
      container_names = []
      source_tag = false
      container_name_include = []
      container_name_exclude = []
      timeout = "5s"
      perdevice = true
      total = true
      docker_label_include = []
      docker_label_exclude = []
      tag_env = []
  description: Una serie de plugins para monitorear los VPS a disposición de las Delegaciones de Alumnos de la UPM.
  name: DA-UPM Monitoring